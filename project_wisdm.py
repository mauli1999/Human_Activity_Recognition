# -*- coding: utf-8 -*-
"""project_WISDM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GpoNVfahDRbVi2Yh6Iiku703b0tIZgjQ
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib
import os
from sklearn.preprocessing import StandardScaler
from google.colab import files

# Define the directory path containing the text files
data_path = "/content/data"

# Get a list of all text files in the directory
text_files = [file for file in os.listdir(data_path) if file.endswith('.txt')]

# Initialize an empty list to store DataFrames
data_frames = []

# Iterate over each text file, read it, and append it to the list
for file in text_files:
    file_path = os.path.join(data_path, file)
    # Assuming the text file has comma-separated values
    data_frames.append(pd.read_csv(file_path, header=None, names=["Subject-id", "Activity", "Timestamp", "x", "y", "z"], sep=","))

# Concatenate all DataFrames in the list into a single DataFrame
combined_data = pd.concat(data_frames, ignore_index=True)

# Display the first few rows of the combined data to verify it was read correctly
print(combined_data.head())

# Load other relevant files as needed
selected_activities = ['A', 'D', 'E']

# Step 3: Filter the Data
# Filter rows with selected activities
filtered_data = combined_data[combined_data['Activity'].isin(selected_activities)]
print(filtered_data)
# Get the rows and columns for phone_gyro_data_1
rows, columns = filtered_data.shape
print("filtered_data Data (Rows, Columns):", rows, columns)

# Step 4: Check if there are enough samples for train-test split
if len(filtered_data) < 2:
    print("Insufficient data for train-test split.")
else:
    # Step 5: Split the Filtered Data
    X_train = filtered_data[["x", "y", "z"]]
    y_train = filtered_data["Activity"]
    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

def preprocess_data(data):
    try:
        # Try converting to float directly
        return float(data)
    except ValueError:
        try:
            # Handle the case where the data contains non-numeric characters
            return float(data[:-1])  # Remove the last character (semicolon)
        except ValueError:
            # If it still fails, return NaN
            return float('nan')

# Apply preprocessing to the relevant columns in X_train and X_test
X_train['x'] = X_train['x'].apply(preprocess_data)
X_train['y'] = X_train['y'].apply(preprocess_data)
X_train['z'] = X_train['z'].apply(preprocess_data)

X_test['x'] = X_test['x'].apply(preprocess_data)
X_test['y'] = X_test['y'].apply(preprocess_data)
X_test['z'] = X_test['z'].apply(preprocess_data)

# Step 4: Build and Train the Model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import numpy as np

# Get predicted labels
y_pred = model.predict(X_test)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(np.unique(y_test)))
plt.xticks(tick_marks, np.unique(y_test), rotation=45)
plt.yticks(tick_marks, np.unique(y_test))

for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > cm.max() / 2. else "black")

plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.tight_layout()
plt.show()

# Step 5: Evaluate the Model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Classification Report:\n{report}")

joblib.dump(model, "/content/trained_random_forest_model.pkl")

model_test = joblib.load("/content/trained_random_forest_model.pkl")

file_path = "/content/sensor_data.txt"  # Replace this with the path to your text file
phone_accel_data = pd.read_csv(file_path, skiprows=1, names=["Timestamp", "x", "y", "z"], sep=",")
#phone_accel_data = pd.read_csv(file_path, skiprows=1, names=["Timestamp", "x", "y", "z"], sep=",")
# phone_accel_data = phone_accel_data.drop(columns=["ax", "ay", "az"])
combine_data = phone_accel_data

print(combine_data)

# Apply preprocessing to the relevant columns
phone_accel_data['x'] = phone_accel_data['x'].apply(preprocess_data)
phone_accel_data['y'] = phone_accel_data['y'].apply(preprocess_data)
phone_accel_data['z'] = phone_accel_data['z'].apply(preprocess_data)

predicted_activities_rf = model_test.predict(phone_accel_data[['x', 'y', 'z']])

print(predicted_activities_rf)

# Define the activity key
activity_key = {
    'A': 'walking',
    'B': 'jogging',
    'C': 'stairs',
    'D': 'sitting',
    'E': 'standing',
    'F': 'typing',
    'G': 'teeth',
    'H': 'soup',
    'I': 'chips',
    'J': 'pasta',
    'K': 'drinking',
    'L': 'sandwich',
    'M': 'kicking',
    'O': 'catch',
    'P': 'dribbling',
    'Q': 'writing',
    'R': 'clapping',
    'S': 'folding'
}

predicted_activities_mapped_rf = []
for activity in predicted_activities_rf:
    if activity in activity_key:
        predicted_activities_mapped_rf.append(activity_key[activity])
    else:
        predicted_activities_mapped_rf.append("Unknown")

# Calculate activity durations for RF model
activity_durations_rf = []
current_activity_rf = predicted_activities_mapped_rf[0]
start_timestamp_rf = combine_data.iloc[0]['Timestamp']

for i in range(1, len(predicted_activities_mapped_rf)):
    if predicted_activities_mapped_rf[i] != current_activity_rf:
        end_timestamp_rf = combine_data.iloc[i-1]['Timestamp']
        activity_durations_rf.append((current_activity_rf, start_timestamp_rf, end_timestamp_rf))
        current_activity_rf = predicted_activities_mapped_rf[i]
        start_timestamp_rf = combine_data.iloc[i]['Timestamp']

# Add the last activity duration for RF model
activity_durations_rf.append((current_activity_rf, start_timestamp_rf, combine_data.iloc[-1]['Timestamp']))

# Output activity predictions and durations for RF model
for activity_rf, start_rf, end_rf in activity_durations_rf:
    duration_rf = end_rf - start_rf
    print(f"Activity predicted using RF model: {activity_rf}, Start: {start_rf}, End: {end_rf}, Duration: {duration_rf}")

# Dictionary to store total durations for each activity from RF model
total_durations_rf = {}

# Calculate total durations for each activity from RF model
for activity_rf, start_rf, end_rf in activity_durations_rf:
    duration_seconds_rf = (end_rf - start_rf) / 1_000_000  # Convert microseconds to seconds
    duration_minutes_rf = duration_seconds_rf / 60  # Convert seconds to minutes
    if activity_rf in total_durations_rf:
        total_durations_rf[activity_rf] += max(duration_minutes_rf, 0)  # Ensure duration is not negative
    else:
        total_durations_rf[activity_rf] = max(duration_minutes_rf, 0)  # Ensure duration is not negative

# Output total time spent on each activity from RF model in hours, minutes, and seconds format
for activity_rf, total_duration_rf in total_durations_rf.items():
    hours_rf = int(total_duration_rf // 60)
    minutes_rf = int(total_duration_rf % 60)
    seconds_rf = int((total_duration_rf - int(total_duration_rf)) * 60)
    print(f"Activity: {activity_rf}, Duration: {hours_rf}:{minutes_rf}:{seconds_rf}")

activity_dict = {
    "Activity": activity_rf,
    "Duration": f"{hours_rf}:{minutes_rf}:{seconds_rf}"
}

uploaded = files.upload()

os.makedirs('/content/frontend', exist_ok=True)  # Create a directory for frontend files
os.rename('Pervasive.html', '/content/frontend/Pervasive.html')  # Move Register.html
os.rename('Pervasive.js', '/content/frontend/Pervasive.js')  # Move Login.html
os.rename('Pervasive.css', '/content/frontend/Pervasive.css')

from IPython.display import HTML  # Import the HTML class

# Load the HTML file from the new directory
html_path = '/content/frontend/Pervasive.html'
with open(html_path, 'r') as f:
    html_content = f.read()

# Display the HTML content
HTML(html_content)

# Load the JavaScript file from the new directory
js_path = '/content/frontend/Pervasive.js'
with open(js_path, 'r') as f:
    js_content = f.read()

# Load the CSS file from the new directory
css_path = '/content/frontend/Pervasive.css'
with open(css_path, 'r') as f:
    css_content = f.read()

from IPython.display import HTML

# Define the file paths
html_path = '/content/frontend/Pervasive.html'
css_path = '/content/frontend/Pervasive.css'
js_path = '/content/frontend/Pervasive.js'

# Read the HTML content
with open(html_path, 'r') as f:
    html_content = f.read()

# Read the CSS content
with open(css_path, 'r') as f:
    css_content = f.read()

# Read the JavaScript content
with open(js_path, 'r') as f:
    js_content = f.read()

# Embed CSS and JavaScript into HTML
html_content_with_css = f'<style>{css_content}</style>{html_content}'
html_content_with_js = f'<script>{js_content}</script>{html_content_with_css}'

# Display the HTML content with CSS and JavaScript
HTML(html_content_with_js)

import matplotlib.pyplot as plt

# Actual times for three activities (Standing, Sitting, Walking)
actual_times = {'Standing': 10, 'Sitting': 30, 'Walking': 5}

# Predicted times for three activities (Standing, Sitting, Walking)
# Example predicted times, replace with your own data
predicted_times = {'Standing': 7.33, 'Sitting': 24.20, 'Walking': 2.32}

# Activities
activities = list(actual_times.keys())

# Actual and Predicted times
actual_values = [actual_times[activity] for activity in activities]
predicted_values = [predicted_times[activity] for activity in activities]

# Plotting the bar graph
bar_width = 0.35
index = range(len(activities))

plt.bar(index, actual_values, bar_width, label='Actual Time')
plt.bar([i + bar_width for i in index], predicted_values, bar_width, label='Predicted Time')

plt.xlabel('Activities')
plt.ylabel('Time (min)')
plt.title('Comparative Bar Graph for Actual and Predicted Times')
plt.xticks([i + bar_width/2 for i in index], activities)
plt.legend()

plt.tight_layout()
plt.show()